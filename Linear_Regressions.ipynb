{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 複数の機械学習ライブラリを用いて線形回帰を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksn/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as core_layers\n",
    "try:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次の2つの回帰式の検証のために人工的に作り出したデータを使う\n",
    "\n",
    "### 線形回帰\n",
    "\n",
    "$ y(x) = a + b_1 \\cdot X_1 + b_2 \\cdot X_2 + b_3 \\cdot X_3 + \\sigma \\cdot \\varepsilon $ \n",
    "\n",
    "ここで $ \\varepsilon \\sim N(0, 1) $ はガウシアンノイズ。また、 $ \\sigma $ はボラティリティを表す。  \n",
    "パラメータの値は以下のように値を選ぶ。（この既知のパラメータを推定してみるということ）  \n",
    "\n",
    "$ a = 1.0 $\n",
    "\n",
    "$ b_1, b_2, b_3 = (1.0,0.5, 0.2) $\n",
    "\n",
    "$ \\sigma = 0.1 $\n",
    "\n",
    "$ X_1, X_2, X_3 $ will be uniformally distributed in $ [-1,1] $\n",
    "\n",
    "\n",
    "### 非線形回帰\n",
    "\n",
    "$ y(x) = a + w_{00} \\cdot X_1 + w_{01} \\cdot X_2 + w_{02} \\cdot X_3 + w_{10} \\cdot X_1^2 \n",
    "+ w_{11} \\cdot X_2^2 + w_{12} \\cdot X_3^2 +  \\sigma \\cdot \\varepsilon $ \n",
    "\n",
    "ここで\n",
    "\n",
    "$ w = [[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]]  $\n",
    "\n",
    "である。また、残りのパラメータは上記の線形回帰のときと同じで、$ X_i $に関しても同様。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_points=10000, n_features=3, use_nonlinear=True, \n",
    "                    noise_std=0.1, train_test_split = 4):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    n_points - number of data points to generate\n",
    "    n_features - a positive integer - number of features\n",
    "    use_nonlinear - if True, generate non-linear data\n",
    "    train_test_split - an integer - what portion of data to use for testing\n",
    "                     - テストに使うデータの割合\n",
    "    \n",
    "    Return:\n",
    "    X_train, Y_train, X_test, Y_test, n_train, n_features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Linear data or non-linear data?\n",
    "    # もしパラメータuse_nonlinearがTrueであれば非線形モデルを用いる\n",
    "    # 今回は使っていない\n",
    "    if use_nonlinear:\n",
    "        # [[w_00,w_01,w_02],[w_10,w_11,w_12]]\n",
    "        weights = np.array([[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]])\n",
    "    else:\n",
    "        # [a, b_1, b_2]\n",
    "        weights = np.array([1.0, 0.5, 0.2])\n",
    "    \n",
    "    bias = np.ones(n_points).reshape((-1,1))\n",
    "    low = - np.ones((n_points,n_features),'float') # 一様分布から取り出された確率変数が取る値の下限\n",
    "    high = np.ones((n_points,n_features),'float')  # 一様分布から取り出された確率変数が取る値の上限\n",
    "        \n",
    "    np.random.seed(42)\n",
    "    X = np.random.uniform(low=low, high=high)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(size=(n_points, 1))\n",
    "    noise_std = 0.1\n",
    "    \n",
    "    if use_nonlinear:\n",
    "        # weights[0,0]とbiasをかけてバイアス項を表すのは本当はよくないとおもわれる\n",
    "        # 本来weights[0,0]はaを表すのではなくてw_00を表しているので（今、どちらも1で同じ値なので結果は変わらない）\n",
    "        Y = (weights[0,0] * bias + np.dot(X, weights[0, :]).reshape((-1,1)) + \n",
    "             np.dot(X*X, weights[1, :]).reshape([-1,1]) +\n",
    "             noise_std * noise)\n",
    "    else:\n",
    "        Y = (weights[0] * bias + np.dot(X, weights[:]).reshape((-1,1)) + \n",
    "             noise_std * noise)\n",
    "    \n",
    "    n_test = int(n_points/train_test_split)\n",
    "    n_train = n_points - n_test\n",
    "    \n",
    "    X_train = X[:n_train,:]\n",
    "    Y_train = Y[:n_train].reshape((-1,1))\n",
    "\n",
    "    X_test = X[n_train:,:]\n",
    "    Y_test = Y[n_train:].reshape((-1,1))\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, n_train, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 3), (7500, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train, X_test, Y_test, n_train, n_features = generate_data(use_nonlinear=False)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpyを使って線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Equationを使って計算している。\n",
    "\n",
    "Normal Equationはよく見る形としてはこんな感じ:  \n",
    "$\\theta = (X^T X)^{-1} X ^{T} y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_f = len(X_train)\n",
    "X = np.hstack((np.ones(num_of_f).reshape((-1,1)),X_train))\n",
    "theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99946227],\n",
       "       [0.99579039],\n",
       "       [0.499198  ],\n",
       "       [0.20019798]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際のデータは切片の値が1, b_1=1.0, b_2=0.5, b_3=0.2として生成されたものなのでかなり正確に推定出来ていることが分かる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearnを使って線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは簡単で分かりやすい。scikit-learnを使う場合はモデルを選んで訓練データとテストデータにフィットさせるという流れらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "reg = lin_reg.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推定された係数の値は次のように確認できる:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99579039, 0.499198  , 0.20019798]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切片は以下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99946227])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowを使って線形回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やはりNormal Equationを使って計算している。\n",
    "\n",
    "Normal Equationはよく見る形としてはこんな感じ:  \n",
    "$\\theta = (X^T X)^{-1} X ^{T} y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_f = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.hstack((np.ones(num_of_f).reshape((-1,1)),X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.25091976,  0.90142861,  0.46398788],\n",
       "       [ 1.        ,  0.19731697, -0.68796272, -0.68801096],\n",
       "       [ 1.        , -0.88383278,  0.73235229,  0.20223002],\n",
       "       ...,\n",
       "       [ 1.        , -0.41969273,  0.7395476 ,  0.49515624],\n",
       "       [ 1.        , -0.15112479,  0.42105835,  0.73537775],\n",
       "       [ 1.        ,  0.95130426,  0.90470301, -0.34934435]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lin_regress(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X_train  - np.array of size (n by k) where n is number of observations \n",
    "                of independent variables and k is number of variables\n",
    "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
    "    \n",
    "    Return:\n",
    "    np.array of size (k+1 by 1) of regression coefficients\n",
    "    \"\"\"\n",
    "    num_of_f = len(X_train)\n",
    "    # add the column of ones\n",
    "    X_np = np.hstack((np.ones(num_of_f).reshape((-1,1)),X_train))\n",
    "    X = tf.constant(X_np, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(Y_train, dtype = tf.float32, name = \"y\")\n",
    "    XT = tf.transpose(X)\n",
    "    \n",
    "    # define theta for later evaluation\n",
    "    theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)), XT), y)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        theta_value = theta.eval()\n",
    "    return theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_tf = tf_lin_regress(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9994622 ],\n",
       "       [0.9957907 ],\n",
       "       [0.49919808],\n",
       "       [0.20019795]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この推定もうまくいっていることが分かる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
